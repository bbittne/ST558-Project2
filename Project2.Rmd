---
title: "ST558 - Project 2"
author: "Li Wang & Bryan Bittner"
date: "`r Sys.Date()`"
output: 
  github_document: default
   
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

```


# Load Packages

We will use the following packages:

```{r}
library(httr)
library(jsonlite)
library(readr)
library(tidyverse)
library(lubridate)
library(knitr)
library(caret)
library(randomForest)
```


# Introduction

This data set summarizes a heterogeneous set of features about articles published by Mashable in a period of two years. 

Our target variable is the shares variable, and predict variables are global_rate_positive_words, global_rate_negative_words, n_tokens_title and so on. 

The purpose of our analysis is to predict the number of shares in social networks (popularity). In this project, we produce some basic (but meaningful) summary statistics and plots about the training data, and fit a linear regression model and an ensemble tree-based model for predicting the number of shares.


# Data

Use a relative path to import the data.

```{r}
newsData<-read_csv(file="../ST558-Project2/OnlineNewsPopularity.csv")
#newsData<-read_csv(file="../Datasets/OnlineNewsPopularity.csv")
head(newsData)
```

Subset the data to work on the data channel of interest

```{r}
#Once we parameterize this file, part of the column name will be passed in as a parameter by the render code. I'm creating a separate field to handle this portion of the column name now and eventually we can just set the parameter to this field and the rest should work.

#Parameter Name will eventually go here instead of "lifestyle"
paramColumnNameType<-"lifestyle"
columnName<-paste("data_channel_is_",paramColumnNameType,sep="")

#According to dplyr help, to refer to column names stored as string, use the '.data' pronoun.
#https://dplyr.tidyverse.org/reference/filter.html
newsDataSubset <- filter(newsData,.data[[columnName]] == 1)

# remove data_channel_is_entertainment,data_channel_is_bus, data_channel_is_socmed ,data_channel_is_tech,data_channel_is_world columns.
newsDataSubset<-newsDataSubset%>%select(-c(15:19))
head(newsDataSubset)
```

## Summarizations

You should produce some basic (but meaningful) summary statistics and plots about the training data you are working with (especially as it relates to your response - aka the 'shares' field)


Start with the basic summary statistics for the 'shares' field.
```{r}
summary(newsDataSubset$shares)
```

Now lets show the Mean, Median, Variance, and Standard Deviation. Notice the Variance and Standard Deviation are both extremely high. This might be something we will have to investigate further
```{r}
newsDataSubset %>% summarise(avg = mean(shares), med = median(shares), var = var(shares), sd = sd(shares))
```

Looking at the different columns in the dataset, there are two that stand out. Generally speaking, people probably aren't going to look at articles that don't have images or videos. Here are the summary stats for the articles grouped on the number of images in the article.

```{r}
newsDataSubset %>% group_by(num_imgs) %>%
summarise(avg = mean(shares), med = median(shares), var = var(shares), sd = sd(shares))
```

Here are the summary stats for articles with videos.
```{r}
newsDataSubset %>% group_by(num_videos) %>%
summarise(avg = mean(shares), med = median(shares), var = var(shares), sd = sd(shares))
```

A scatter plot with the number of shares on the y-axis and n_tokens_title on the x-axis is created:

```{r}
g <- ggplot(newsDataSubset, aes(x = n_tokens_title, y = shares))
g + geom_point()
```


# Modeling

## Random Forest Model and Explanation - Bryan

## Boosted Tree Model and Explanation - Li

## Linear Regression Explanation - Bryan

# Comparison

# Automation
